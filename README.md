This repository contains a custom deep learning framework. The framework covers various essential components for building and training neural networks, including computational graph creation, linear layers, activation layers, mini-batch gradient descent, L2 loss, cross-entropy, and node gradient calculation.

## Features

- **Computational Graph Creation**: Implementing a computational graph to represent neural network architectures.
- **Linear Layer**: Custom implementation of linear layers (fully connected layers) for forward and backward propagation.
- **Activation Layer**: At this time support only Sigmoid.
- **Mini-Batch Gradient Descent**: Implementation of mini-batch gradient descent for optimizing neural network parameters.
- **Loss Functions**: Support for L2 loss and cross-entropy loss functions.
- **Node Gradient Calculation**: Computing gradients of the loss function with respect to the nodes in the computational graph.
